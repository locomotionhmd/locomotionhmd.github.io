<h1>&nbsp;</h1>

<h1 style="text-align:center"><span style="font-family:Georgia,serif"><span style="color:#2980b9"><strong>Systematic Literature Review on Effective Locomotion through Hardware Transformation&nbsp;</strong><strong>in Head-Mounted Device: A Review Study&nbsp;</strong></span></span></h1>

<p style="text-align:center"><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif"><small><span style="color:#000000"><strong>Pawankumar Gururaj Yendigeri, </strong>Center of VLSI and Embedded Systems Technologies, IIIT Hyderabad, India (pawankumar.yendigeri@research.iiit.ac.in)</span></small></span></span></p>

<p style="text-align:center"><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif"><small><span style="color:#000000"><strong>Raghav Mittal, </strong>Software Engineering Research Center, IIIT Hyderabad, India (raghav.mittal@research.iiit.ac.in)</span></small></span></span></p>

<p style="text-align:center"><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif"><small><span style="color:#000000"><strong>Sai Anirudh Karre, </strong>Software Engineering Research Center, IIIT Hyderabad, India (saianirudh.karri@research.iiit.ac.in)</span></small></span></span></p>

<p style="text-align:center"><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif"><small><span style="color:#000000"><strong>Raghu Babu Reddy, </strong>Software Engineering Research Center, IIIT Hyderabad, India (raghu.reddy@iiit.ac.in)</span></small></span></span></p>

<p style="text-align:center"><span style="font-size:18px"><span style="font-family:Arial,Helvetica,sans-serif"><small><span style="color:#000000"><strong>Syed Azeemuddin, </strong>Center of VLSI and Embedded Systems Technologies, IIIT Hyderabad, India (syed@iiit.ac.in)</span></small></span></span></p>

<p>&nbsp;</p>

<ul>
	<li style="text-align:justify"><span style="font-family:Arial,Helvetica,sans-serif"><span style="color:#9b59b6"><span style="font-size:16px"><strong>BACKGROUND:</strong></span></span><span style="color:#000000"><span style="font-size:16px">&nbsp;</span><span style="font-size:14px">Most VR practitioners who build 3-DOF supported HMD struggle to excel in running rich VR content. However, the slightest hardware transformation will significantly impact HMD adoption. Many relevant studies have been conducted for locomotion in VR; however, contributions in hardware transformation of locomotion technique&nbsp;are&nbsp;not considerably addressed.&nbsp;This study is scope to understand the hardware transformation of HMDs from 3-DOF to 6-DOF without additional external haptic support. &nbsp;Learning from our research will assist future targetted HMD developers develop customizable and configurable HMDs for focused applications. This study paves the way for hassle-free substantial hardware transformation of 3-DOF HMDs on supporting 6-DOF in the future. We also illustrate our observations through a taxonomy of tracking methods through hardware-based HMDs. This taxonomy will also help VR practitioners to plan and transform their HMDs to support other motion tracking for effective locomotion.&nbsp;</span></span></span></li>
</ul>

<p>&nbsp;</p>

<ul>
	<li style="text-align:justify"><span style="font-family:Arial,Helvetica,sans-serif"><span style="color:#9b59b6"><strong><span style="font-size:16px">SEARCH STRATEGY:</span></strong></span><span style="color:#000000"><strong>&nbsp;</strong><span style="font-size:14px">We conducted our systematic review study by considering the guidelines proposed by Kitchenham et al. As part of our review, we utilized the PICOC (Population, Intervention, Comparison, Outcome, and Context) method to establish our study&#39;s context and relevance. This also helped us design our research questions, search string, and search protocol. Table 1&nbsp;illustrates the PICOC details of our study.</span>&nbsp;&nbsp;</span></span></li>
</ul>

<table align="center" border="1" cellpadding="1" cellspacing="1" style="width:898px">
	<tbody>
		<tr>
			<td style="text-align:center; width:254px"><span style="font-size:14px"><span style="color:#000000"><strong>Criteria</strong></span></span></td>
			<td style="text-align:center; width:629px"><span style="font-size:14px"><span style="color:#000000"><strong>Description</strong></span></span></td>
		</tr>
		<tr>
			<td style="text-align:center; width:254px"><span style="font-size:14px"><span style="color:#000000"><strong>Population</strong></span></span></td>
			<td style="width:629px">
			<p style="text-align:center"><span style="font-size:14px"><span style="color:#000000">For VR HMD users willing to switch locomotion from 3-DOF to 6-DOF</span></span></p>
			</td>
		</tr>
		<tr>
			<td style="text-align:center; width:254px"><span style="font-size:14px"><span style="color:#000000"><strong>Intervention</strong></span></span></td>
			<td style="text-align:center; width:629px"><span style="font-size:14px"><span style="color:#000000">Motion tracking methods for VR locomotion</span></span></td>
		</tr>
		<tr>
			<td style="text-align:center; width:254px"><span style="font-size:14px"><span style="color:#000000"><strong>Comparison</strong></span></span></td>
			<td style="text-align:center; width:629px"><span style="font-size:14px"><span style="color:#000000">Comparison between tracking methods based on hardware requirement, working, performance and target application</span></span></td>
		</tr>
		<tr>
			<td style="text-align:center; width:254px"><span style="font-size:14px"><span style="color:#000000"><strong>Outcome</strong></span></span></td>
			<td style="text-align:center; width:629px"><span style="font-size:14px"><span style="color:#000000">Studies that employed motion tracking methods for locomotion in VR</span></span></td>
		</tr>
		<tr>
			<td style="text-align:center; width:254px"><span style="font-size:14px"><span style="color:#000000"><strong>Context</strong></span></span></td>
			<td style="text-align:center; width:629px"><span style="font-size:14px"><span style="color:#000000">Academia, VR community and other empirical studies</span></span></td>
		</tr>
	</tbody>
</table>

<p style="text-align:center"><span style="color:#000000">&nbsp;</span><span style="color:#9b59b6">Table 1. PICOC details of our review study</span></p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>i) Research Questions</strong>: </span></span><span style="font-size:14px"><span style="color:#000000">The primary objective of our review study is to summarize the motion tracking methods served by HMDs for conducting effective locomotion in VR applications. Below research questions are expressed to capture the insights&nbsp;of our objective.&nbsp;</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<strong>RQ1 -&gt;&nbsp;</strong>What types of motion tracking methods are operated for head tracking by an HMD for VR applications?</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp; &nbsp; &nbsp; &nbsp; RQ2 -&gt;&nbsp;</strong>What are the hardware components required for transforming a VR HMD from 3-DOF to 6-DOF motion-tracking?</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp; &nbsp; &nbsp; &nbsp; RQ3 -&gt;</strong>&nbsp;What are the metrics practised to evaluate the effectiveness of motion tracking methods after transforming the VR HMD from 3-DOF to 6-DOF?</span></span></p>

<p>&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>ii) Search Strings:</strong></span></span><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp;</strong>We used our research questions to deduce our search strategy. We first created a list of keywords relevant to the research questions. We later generalized the keywords by streamlining the scope of the review. We finalized the search string by considering all possible synonyms and have divided them into three parts, i.e.&nbsp;S1, S2 and S3. Below is our final Search string:</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp; &nbsp; &nbsp; &nbsp;</strong><strong> S1</strong><em>: &ldquo;Virtual Reality&rdquo; OR &ldquo;VR&rdquo;</em></span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; <strong>S2</strong><em>: &ldquo;Head-mounted device&rdquo; OR &ldquo;Head-mounted display&rdquo; OR &ldquo;HMD&rdquo; OR&ldquo;Head-mounted display&rdquo; OR &ldquo;Head-mounted device&rdquo; OR &ldquo;headset&rdquo; OR &ldquo;display&quot;</em></span></span></p>

<p><span style="font-size:14px"><span style="color:#000000"><em>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;OR &ldquo;projection&rdquo; </em></span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; <strong>S3</strong><em>: &ldquo;Degree of Freedom&rdquo; OR &ldquo;Degrees of Freedom&rdquo; OR &ldquo;DOF&rdquo; OR &ldquo;3 DOF&rdquo; OR &ldquo;3-DOF&rdquo; OR&nbsp;&ldquo;3DOF&rdquo; OR &ldquo;6DOF&rdquo; OR &ldquo;6-DOF&rdquo; OR &ldquo;6DOF&rdquo; OR </em></span></span></p>

<p><span style="font-size:14px"><span style="color:#000000"><em>&nbsp; &nbsp; &nbsp; &nbsp; &ldquo;motion&nbsp; tracking.&rdquo; OR &ldquo;motion-tracking&rdquo; &nbsp;OR &ldquo;head tracking&rdquo; OR &ldquo;head-tracking</em></span></span></p>

<p>&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>iii) Search Quality Assessment:</strong></span></span><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp;</strong>We designed a set of ten interrogative questionnaires to aid our review to filter the research papers based on their relevance, reliability, and nature of the study. This&nbsp;questionnaire awards a Yes or No, i.e., 1 or 0 as a score, where yes represents review consideration and No for ignore for review consideration. A given paper requires&nbsp;a score of 6 for review consideration. Our quality questionnaires are explained as follows:&nbsp;</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(1)&nbsp;Is the tracking methodology novel or follow-up research?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(2)&nbsp;Is there clarity in explaining the objective of the research?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(3)&nbsp;Is it possible to realize the study as a real-life application?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(4)&nbsp;Was the application/necessity of the method addressed in the paper?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(5)&nbsp;Is the data provided in the study addressing the objectives of the research?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(6)&nbsp;Is the motion tracking method validated using a study?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(7)&nbsp;Was the validation technique for motion tracking explained appropriately with description and reference?&nbsp;&nbsp; &nbsp;</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(8)&nbsp;Is the information provided enough to replicate the design?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(9)&nbsp;Is the study of value for further research?</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(10)&nbsp;Is there findings, limitations, future scope, or discussions in the paper?&nbsp;</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000">Apart from the search quality assessment, we employed the below inclusion and exclusion criteria to further filter our search output.</span></span></p>

<p>&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>iv) Inclusion Criteria:&nbsp;</strong></span></span><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp;</strong>Only research papers written in English are considered for our study. Only papers published between 2010 and 2021 are considered. The study that&nbsp;provides transparent information about the design, implementation and evaluation of motion tracking techniques in VR is considered. Papers that discuss and authenticate&nbsp;the motion tracking accuracy based on some user-study are considered.&nbsp;</span></span></p>

<p>&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>v) Exclusion Criteria:&nbsp;</strong></span></span><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp;</strong>Studies that are not available in Full Text are not considered for review. &nbsp;Research contributions published as articles, magazines, review Notes,&nbsp;datasets, archives, books, book chapters, reference works are excluded from the study as they are informal and incomplete in regards to the goal of our search. Studies&nbsp;involving motion tracking using external haptics, external controllers, or objects are excluded from our research. &nbsp;Paper without proper research to validate the hardware is excluded.</span></span></p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>vi) Results:</strong></span></span><span style="font-size:14px"><span style="color:#000000"><strong> </strong>We conducted our literature search in digital libraries like ACM, Springer, IEEEXplore, ScienceDirect, Wiley. We extracted relevant research papers&nbsp;from ACM, Springer, and IEEEXplore. We had to exclude ScienceDirect and Wiley from du<img alt="" src="/images/img3.JPG" style="border-style:solid; border-width:2px; float:right; height:250px; margin:2px; width:418px" />plicates, and the results are relatively low compared to other digital libraries.&nbsp;These two libraries have minor literature on hardware and user interaction in VR Domain. We have considered only research articles only for our review study.&nbsp;We conducted an extensive search on the respective databases&nbsp;by following our search strategy.&nbsp;We extracted our search results in multiple levels by applying inclusion and exclusion criteria. As part of the initial search, we pulled 998 papers from ACM digital library, 726 documents from IEEEXplore, and 1285 papers from Springer Journal. We&nbsp;conducted a peer review and have reportedly removed seven duplicates across the search results. We extracted 3009 papers in total as part of the initial search.&nbsp;As part of our first iteration of screening, we filtered papers based on title and abstract. We excluded around 2235 papers and considered 767 papers as part&nbsp;of this step. In the second iteration of screening, we conducted a full-text review of the paper based on the context of our search and have further filtered the search results&nbsp;to 70 papers by excluding 697 papers. We conducted a detailed study on the filtered papers regarding relevance, technique, and metrics as part of the final consideration.&nbsp;We filtered the results to 14 papers, and after further snowballing on related work, 17 papers were finalized for our review study. All the authors reproduced the search individually&nbsp;and applied the filters in respective iterations. All the authors have arrived at a similar conclusion towards the search results. All the supplementary&nbsp;material of our search iterations and review are available for replicating our study.</span></span></p>

<p>&nbsp;</p>

<p>&nbsp;</p>
<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><img alt="" src="/images/img1.JPG" style="height:633px; margin-left:65px; margin-right:65px; width:1000px" /></span></span></p>

<p style="text-align:center"><span style="color:#9b59b6"><span style="font-size:14px">Table 2. Finalised studies for the review</span></span></p>

<ul>
	<li style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>DISCUSSION:</strong></span></span><span style="font-size:14px"><span style="color:#000000"><strong>&nbsp;</strong>By considering the finalized research papers, we conducted an elaborated study to record our findings. In this section, we discuss our insights in regards to respective research questions as follows:&nbsp;</span></span></li>
</ul>

<p>&nbsp;</p>

<p><span style="color:#000000"><span style="font-family:Georgia,serif"><span style="font-size:16px"><strong><span style="background-color:#f1c40f">RQ1- What types of motion tracking methods are operated for head tracking by an HMD for VR applications?</span></strong></span></span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp; &nbsp;Table 2 illustrates the HMDs transformed to 6-DOF support with respective details on their hardware setup, working principle of the underlying motion tracking method to facilitate locomotion in VR applications. It also categorizes these HMDs based on the target VR application. Table 2 also provides the year of publication along with its reference. We observe that the motion tracking methods are enhanced by hardware transformation largely for targeted applications like training, simulation, and multi-user application. All these hardware transformations are scaled and scoped to HMDs without any external haptic support. In almost all cases, the HMDs primarily supported locomotion techniques like rotational, translation, and axial. We further discuss the effectiveness of the underlying hardware of these transformed HMDs as part of RQ3.&nbsp;</span></span></p>

<p>&nbsp;</p>

<p><span style="color:#000000"><span style="font-size:16px"><span style="font-family:Georgia,serif"><strong><span style="background-color:#f1c40f">RQ2- What are the hardware components required for transforming a VR HMD from 3-DOF to 6-DOF motion tracking?</span></strong></span></span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">&nbsp; &nbsp; &nbsp;&nbsp;Considering the insights from the reviewed papers, we address this research question by proposing a taxonomy of locomotion techniques based on hardware support. The underlying hardware is used to conduct locomotion through motion tracking methods in a given HMD. The motive behind illustrating the taxonomy is to help VR practitioners establish a relationship between the hardware needs of an HMD and choose a suitable locomotion method. Lisa Prinz et al. conducted an initial review of primary studies that involved different taxonomies related to locomotion in VR. Previously proposed taxonomies are based on parameters like walking, redirection, teleportation, haptics, hand gestures, and materialistic feedback. These proposed taxonomies of locomotion are either human-centred or software-centred. They do not factor in the customization of HMDs. Data captured in our review study helped classify the locomotion techniques based on motion tracking by considering the customized HMD hardware.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">The characteristics of the hardware system can be defined by the performance of sensors, actuators, control systems, and the processing unit. Considering these hardware characteristics, we propose a taxonomy for locomotion techniques as illustrated in Fig 2 Based on captured review information, we classify the hardware-based locomotion techniques for HMDs into three main categories as shown in the figure. They are inside-out, outside-in, and mixed tracking. As part of our initial classification, we considered parameters like DOF, peripherals, and transfer function for taxonomy. However, we limited our taxonomy to tracking device&#39;s position only, as it will extensively help VR practitioners choose the best locomotion technique for their respective HMD. As shown in Fig 2, the boxes in blue are types of respective locomotion techniques categorized as Inside-out, Outside-In, and Mixed. The boxes in green are the instances or examples of these respective types listed in blue boxes. For example, &#39;Navichair&#39; and &#39;Tapping in Place&#39; are instances of Inertial based locomotion methods supported by the underlying hardware categorized as Inside-Out tracking.</span></span></p>

<p><span style="font-size:14px"><span style="color:#000000"><img alt="" src="/images/taxonomy.JPG" style="border-style:solid; border-width:2px; height:359px; margin-left:100px; margin-right:100px; width:1000px" /></span></span></p>

<p style="text-align:center"><span style="color:#9b59b6"><span style="font-size:14px">Figure 2.&nbsp;Taxonomy of the locomotion techniques based on motion tracking hardware</span></span></p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>Inside-Out tracking</strong> -</span></span><span style="font-size:14px"><span style="color:#000000"> The sensors are located on the hardware (HMD) or the user peripherals as part of the Inside-Out tracking. Based on our review, three out of seventeen (17.6\%) locomotion techniques belong to inside-out tracking. The inside-out tracking can be further divided into two groups based on the hardware description: inertial and laser-based tracking. Inertial tracking involves analysis based on Inertial-Measurement-Unit (IMU) to track the rotational and translational locomotion in VR HMDs. They are primarily mounted to track the head movements of the user. However, they are not immune to external noise and need a compensation mechanism to counter motion sickness-related problems.[15] On the other hand, laser-based systems like lighthouse tracking use rectangular base stations as reference points to accurately track the user&#39;s position and orientation. These are user-centric, and the data points are gathered based on user stimuli.[13]&nbsp;</span></span><br />
<br />
<span style="font-size:16px"><span style="color:#9b59b6"><strong>Outside-In tracking </strong>- </span></span><span style="font-size:14px"><span style="color:#000000">The sensors are placed externally, preferably in a stationary position, and are not administered directly on the user&#39;s device as part of Outside-In tracking. This locomotion technique is observed to be dominant in practice with nine out of seventeen (52.9\%). As per our review, the outside-in tracking can be further classified into three groups. They are mechatronics, optical and hybrid systems. The studies involving redirected actions using mechanical instruments like treadmill, cycle, hamster ball, or suspended walking using elastic can be categorized as mechatronics systems [7][6][14]. Locomotion that involves camera-based tracking is categorized into optical systems. Considering the working principle of the camera setup, the optical systems can be further subdivided into two groups: filter and machine-learning (ML) based techniques. The filter-based techniques used colour tracking or projection-based detection methods [4], while object tracking and data prediction are achieved using neural networks [10]. Further studies on simulation of motion using mechanical instruments followed by prediction models using ML tools are classified as hybrid systems [8][12].</span></span><br />
<br />
<span style="font-size:16px"><span style="color:#9b59b6"><strong>Mixed tracking</strong>-</span></span><span style="font-size:14px"><span style="color:#000000"> Further studies have found to be following mixed-methods i.e., they employ both Inside-Out and Outside-In tracking. We categorized them as Mixed Tracking methods. Five out of seventeen (29.4\%) locomotion techniques use the user as a receiver and an external point as a transmitter to track position and orientation. Considering the working principle of these systems, we further divided them into three groups: infrared, acoustic, and wireless-tracking systems. Infrared tracking involves locomotion using remote communication utilizing IR cameras [11]. In some cases, position tracking was conducted using the IR LED&#39;s on the user body using an external camera [20]. The tracking involves Electro-Magnetic(EM) transmission using a base station [16][18]. These are classified as wireless tracking methods. A novel tracking method for localization using audio inputs(stereo speakers) is categorized as acoustic tracking [19].</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="color:#000000"><span style="font-family:Georgia,serif"><span style="font-size:16px"><strong><span style="background-color:#f1c40f">RQ3:What are the metrics practised evaluating the effectiveness of motion tracking methods after transforming HMD from 3 to 6-DOF?</span></strong></span></span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Table 3 illustrates the evaluation details of the effectiveness of motion tracking methods after transforming the VR HMD from 3-DOF to 6-DOF. Table 3 is a matrix table with the measures listed in the first row and first column grouped by the citation of the respective paper that employs these measures. The measure listed in the first row is the empirical method used to conduct the evaluation. The measure listed in the first column describes the metrics gathered to understand the effectiveness of the respective motion tracking method after transforming the HMD from 3-DOF to 6-DOF. We address this research question we categorized the research contributions based on the type of the empirical study. We also present the underlying participant experiences and metrics used by VR practitioners.&nbsp;</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><img alt="" src="/images/img2.JPG" style="height:633px; margin-left:65px; margin-right:65px; width:1000px" /></span></span></p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:14px">Table no 3 Evaluation and Metrics for Locomotion Techniques</span></span></p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>Exploratory Studies</strong>- </span></span><span style="font-size:14px"><span style="color:#000000">The following evaluations are conducted using Sports VR applications like basketball, Jogging In-place, and Walking-by-Cycling.&nbsp;<br />
Robert Wang et al. used a two-camera system in real-world indoor and outdoor environments for various activities and lighting conditions. They conducted a focused group evaluation, including basketball players with 3-DOF HMD wearing coloured t-shirts set to be detected by these two camera systems. This camera input is sent as locomotion feedback to the HMD. &nbsp;They captured footage in a dimly lit indoor basketball court through a glass panel of a squash court. Their study was easy to set up with less use of additional lights or equipment [4]. They managed to capture Position accuracy, Drift measure, Precision, and System stability to understand the effectiveness of this setup.&nbsp;</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Sam Tregillus et al. have conducted a comparative study of all Walk-In-Place (WIP) methods as part of their study. Several such studies exist that compared WIP with joystick-based virtual locomotion. However, Sam Tregillus et al. presumed that comparisons of WIP methods involving extensive instrumentation are not helpful as the users of mobile VR do not access such instrumentation. They created VR-STEP that is hands-free and requires no instrumentation. It is more meaningful to compare its performance with another hands-free navigation method like look down to move (LDTM), widely used in several VR apps. Here, the users toggle a button at their feet by briefly looking down at it, then back it up. When activated, the user will move with a fixed horizontal velocity in the direction of their gaze. Similar to other WIP evaluations, they compared VR-STEP to LDTM by having users perform several navigation tasks [5]. They used a Jogging-Inplace VR sport application to conduct the study. They captured track resolution, Motion-to-Photon (M2P) latency and conducted a Statistical analysis to evaluate their 3-DOF HMD.&nbsp;</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Jann Freiwald et al. conducted a focused group study using their 3-DOF HMD with a non-swivelling chair setup. 20 participants (Mean = 30.6, SD = 6.82, 7 female) took part in the experiment. The mean time per participant was about 60 minutes. They build a Walking-by-Cycling sports application using Unity3D. The rendered scene is run on HTC Vive Pro and a non-swivelling chair to seat the participants within the tracking space for the bike and joystick conditions. The participants are asked to stand for the teleportation condition. Standing was required to let the participants use their full head and body proprioception for angular estimation as a baseline to test against. Depending on the condition, they used an Xbox One Controller or the HTC Vive Wand for input [6]. Response Time, Force Feedback, Track resolution, and Drift measure to evaluate the effectiveness of the locomotion.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>Computational Studies</strong>- </span></span><span style="font-size:14px"><span style="color:#000000">The following evaluations are Computational and Parametric studies using Omnidirectional treadmill and object tracking.<br />
Razvan Boboc et al. conducted an exploratory study to examine locomotion using the neural-network-based algorithm. Six participants took part in this study in a virtual environment over an Omni-directional treadmill simulating the sense of steep in the hill or slove in a cave using a 3-DOF HMD. The position and orientation of the user&#39;s feet are captured using the motion tracking system. These are input features of the algorithm. Later, the data is processed to extract the angle between the foot and tibia; the foot&#39;s orientation regards the reference position for the right and left rotation of the Omni-directional treadmill. Using Matlab Simulink, the authors have modelled positions of the motors related to a reference factor and a parameter for the scenario, i.e., the model is used to tilt the platform depending on the inclination angle of hills scenarios. For choosing the number of neurons, the neural network is trained in Matlab. The number of neurons in the hidden layer is reduced until the error can be accepted [7]. They captured metrics like position and rotation accuracy, precision. They also conducted statistical analysis to understand the significance of their data points.&nbsp;</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Boguslaw Rymut et al. conducted an exploratory computational study on object tracking in VR Sence based on a real-time multiuser interface using a 3-DOF HMD. Their algorithm&#39;s performance has been evaluated on sequences with walking persons. They demonstrated that the average speed-up of GPU over CPU is about 7.5. The overall time taken by PSO searching for the best matching image is far shorter than the time needed for evaluation of the fitness function, which is about 0.9 ms [8]. They captured track resolution, portability, precision, motion-to-photon (M2P) latency, and response time metrics. They conducted statistical analysis to understand the significance of their data points.&nbsp;</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>Cognitive Studies</strong>-</span></span><span style="font-size:14px"><span style="color:#000000"> The following evaluations are Cognitive studies using Suspended walking and Walking-in-Place.<br />
Benjamin Franks et al. conducted a focused group assessment with 18 test persons aged 22 to 30 years (average 26.3). Seven of the participants were male, eleven of them were female. The participants are instructed to play a customized level in the game &#39;Portal 2&#39; using a 3-DOF HMD. The level consisted of an obstacle course specifically designed for the experiment using a level editor &nbsp;[9]. After the game completion, they captured the feedback to evaluate the hardware based on drift measure, track resolution, force feedback, and system stability. The response revealed that none of the participants found the suspension setup most comfortable. &nbsp;Some participants criticized that contrary to WIP, the setup restricted the backward locomotion.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Luis Bruno et al. conducted a cognitive study using the OptiTrack motion system. The experiment involved was divided into three segments. Prior to the test, &nbsp;the participants are asked to take a pre-test questionnaire to gather each participant&#39;s demographic and navigation skills data. The participant was made comfortable with the environment by performing travel and stopping tasks. The actual test involved travelling all nine paths and making stops before each target as early as possible [10]. The path was repeated in case of system error or difficulty. After the task, the participants were subjected to the post-test questionnaire to get feedback about their experience. The metrics evaluated using the experiment are drift measure, switching rate, interface network, and response time.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>Multi-User Applications</strong>-</span></span><span style="font-size:14px"><span style="color:#000000"> The following evaluations are Multi-user applications using infrared markers and markerless multi-view tracking.<br />
Wenhui Xu et al. performed a focused group assessment using two individual experiments based on the parameters [11]. The first experiment uses three infrared cameras with a resolution of 1280 x 720 pixels. The participant with the LED module is made to stand three meters away from the cameras. The test was conducted for varying positions and orientations of the participant. The observations suggested that fluctuations do not alter the behaviour of the VR display. The second experiment tests the data refresh rate of the system. They experimented with varying resolutions of display for three cameras and a four-camera setup. The results show that resolutions have a slight effect on the accuracy in the indoor environment. The metrics captured in both experiments are positional accuracy, rotational accuracy, precision, response time, and system stability.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Dylan Bicho et al. conducted a user-centred study and proposed a method using four Microsoft Kinect sensors [12]. The intent was to capture the locomotion of the participant in the different orientations using a 3-DOF HMD. The participant was asked to perform individual tasks like walking straight, following a square-shaped path in a closed-loop, moving in a random path with sudden body or head motions or standing stationary on a single leg with arms wide open. The metrics captured in the experiment are drift measure, track resolution, portability or customization, learning curve, and switching rate.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>Redirected Motion</strong>-</span></span><span style="font-size:14px"><span style="color:#000000"> The following evaluations are conducted using redirected motion applications like NaviChair, Vitrusphere and Tapping-in-Place.&nbsp;<br />
Alexandra Kitson et al. conducted a user-centred study to evaluate the factors responsible for motion sickness in NaviChair [13]. The participants tested for two locomotion techniques in the experiment. The first experiment involved motion using a user-powered swivel chair called NaviChair. The participants can move forward by tilting the chair forward and rotating the chair to rotate in the virtual environment. The second experiment involved a similar set of locomotions, but the joystick was used as the input device. The observations concluded that NaviChair did not help the participants localize and adjust to the virtual environment. The metrics evaluated using both experiments are drift measure, learning curve, interface network, M2P latency and statistical analysis.</span></span></p>

<p style="text-align:justify"><br />
<span style="font-size:14px"><span style="color:#000000">Mahdi Nabiyouni et al. conducted a simulation-based study using a suspended sphere called Virtusphere [14]. The user&#39;s walking is mapped to a viewpoint translation in the virtual scene. They performed a comparative analysis of semi-natural techniques like Virtusphere with an entirely natural technique like walking and artificial technique using a game controller. The analysis suggested that the Virtusphere method was significantly slower and less accurate than the other two techniques. The parameters involved for the comparative analysis were drift measure, rotation accuracy, force feedback and system stability.</span></span></p>

<p style="text-align:justify"><br />
<span style="font-size:14px"><span style="color:#000000">Marian Hudak et al. did the comparative analysis using a customized CAVE setup [15]. They used the 250-degree panoramic view to simulate the surface of the cave as a virtual environment. The participant was asked to perform standard walking and rotation movements. The forward movement was represented on the central tile, and step-aside rotation tiles represented pan rotation movements. The metrics captured in the analysis were position accuracy, precision, noise immunity, interface network and response time.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>Training - </strong></span></span><span style="font-size:14px"><span style="color:#000000">The following evaluations are conducted using training applications like Electromagnetic tracking and Elastic-move.&nbsp;<br />
Markus Zank et al. did a comparative study for walking in a straight line with the old autonomous tracking system [16]. The comparison was made primarily on parameters such as signal for foot movements, base&#39;s movement along the walking direction and movements in upward and sideward direction. The metrics evaluated in the study were drift measure, rotational accuracy, noise and power analysis, system stability and statistical analysis.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Da-Chung Yi et al. conducted a focused group study to evaluate the elastic-move system [17]. The experiment was performed using Simulation Sickness Questions (SSQs) to validate the use of Elastic-Rope and Elastic-Box in VR. The participant was asked to move from a base point to the route ends in a customized virtual environment. The duration of the entire experiment is about 15 minutes. The metrics evaluated for successful motion tracking were rotation accuracy, learning curve, force feedback and noise immunity.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Shantanu Barai et al. did an experimental analysis to localize the participant using an EM-based Tx-Rx system [18]. The EM transmitter was set up at a stationary point, and the secondary coil was mounted on the custom 3-DOF HMD. The experiment is carried out with the varied location of the secondary coil in the X-Y plane. The Z-value is kept constant and is compensated by transformation. The metrics captured using the experiment are position accuracy, drift measure, noise immunity, power and statistical analysis.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>Simulation Studies</strong>-</span></span><span style="font-size:14px"><span style="color:#000000"> The following evaluations are conducted using Simulation-based VR applications like tracking using acoustic and infrared LED setup.&nbsp;<br />
Majed Al Zayer et al. used two acoustic speakers as the communication model to track the user&#39;s location who wears a 3-DOF HMD. They conducted a focused group evaluation for StereoTrack with a smartphone-based microphone to record ultrasonic tones. Multiple tones with varied frequencies were played on three different speaker interfaces to analyze the values [19]. They succeeded in verifying the hardware by measuring positional accuracy, rotational accuracy for 180 degrees, noise immunity, power, and statistical analysis.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">Rasmus Eklund et al. conducted a comparative study for infrared tracking systems based on tests inspired by the Brimijoin experiment. The experiment confirmed that the participants with 3-DOF HMDs slightly moved their heads back and forth at about 15 degrees compared to no head movement. They repeated the experiment to see if participants could notice the degree of externalization once they stopped moving their heads [20]. They captured rotational accuracy, switching rate, interface network, and system stability to evaluate the performance of the hardware.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>Note-</strong></span></span></p>

<p style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>Strategizing Hardware Transformation:</strong></span></span><span style="font-size:14px"><span style="color:#000000"> We presume that the observations captured from the above research questions will provide VR practitioners with a reasonable choice for hardware transformation of their 3-DOF HMD. We systematically structured our observations so that the VR practitioners can understand the prevailing practices and channelize their HMD needs by picking up the desired evaluation method and metric to judge their transformed HMD. We have ensured that our complied taxonomy is compact and easy to comprehend the locomotion techniques for better hardware transformation.&nbsp;</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<ul>
	<li style="text-align:justify"><span style="color:#9b59b6"><span style="font-size:16px"><strong>RELATED WORK:</strong></span></span></li>
</ul>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000">In the past couple of decades, research on locomotion in the virtual environment started gaining its pace. Initially, the navigation in the virtual world was restricted to 3-DOF. Eventually, researchers focused on the user&#39;s other locomotive or navigation feedback to enhance involvement and immersive experience in VR. Many motion tracking techniques were implemented based on actions like walking, steering, selection and manipulation. Al Zayer et al. surveyed multiple tracking methods and discussed their strengths, weaknesses and application to provide an overview for the researchers to apply a particular technique [28]. When it comes to movements that can be employed in VR using locomotion, there is a need for proper classification based on the body organs involved, the extent of the action and its repeatability. Mahdi Nabiyouni et al. proposed a taxonomy of walking based locomotion techniques in VR [27]. This work with comparative analysis provides insight to the researchers and system designers into choosing walking techniques and performing experiments to evaluate them. Lisa Prinz et al. carried out a review and analysis of 29 papers providing locomotion techniques taxonomies. The work inspires the researchers to develop taxonomies in coming up with a novel tracking methodology [21].&nbsp;<br />
\par Heni Cherni et al. conducted a review for 22 motion tracking methods from 2012 to 2019 and provided guidelines to choose the method based on the user&#39;s application. The research was based on the HCI aspect of the VR locomotion and proposed a taxonomy based on user body-centred, external peripheral and mixed methods. The role of user body-centred motions and their relation to motion sickness were some of the paper&#39;s significant contributions. VR locomotion and sickness induced by it needs to be evaluated and corrected. Thomas Gemert et al. highlighted some key components to quantify VR sickness and metrics to counter them [29]. However, these reviews on VR locomotion do not discuss the device parameters and the hardware requirements for designing a particular motion tracking system. The data relating to the device&#39;s operating range, the ability of the sensors, and its relation to the target application are essential viewpoints for a researcher developing a novel tracking method. As a part of the review, we tried to address the hardware aspect for the heuristic replication of the method.</span></span></p>

<p style="text-align:justify">&nbsp;</p>

<ul>
	<li style="text-align:justify"><span style="font-size:16px"><span style="color:#9b59b6"><strong>REFERENCES:</strong></span></span></li>
</ul>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><strong>[1] </strong>B. Kitchenham, P. Brereton, D. Budgen, M. Turner, J. Bailey, and. G. Linkman, &ldquo;Systematic literature reviews in software engineering- A systematic literature review,&rdquo; Information &amp; Software Technology, vol. 51, no. 1, pp. 7&ndash;15, 2009.<br />
<strong>[2]</strong> C. Wohlin, &ldquo;Guidelines for snowballing in systematic literature studies and a replication in software engineering,&rdquo; in Proceedings of the the18th International Conference on Evaluation and Assessment in Software Engineering, EASE &rsquo;14, (New York, NY, USA), Association for Computing Machinery, 2014.<br />
<strong>[3]</strong> &ldquo;Supplement data.&rdquo;https://github.com/anonymousauthor362/SLR-tools.git, October 2021.<br />
<strong>[4]</strong> R. Wang, S. Paris, and J. Popovi ́c, &ldquo;Practical Color-Based MotionCapture,&rdquo; in Proceedings of the 2011 ACM SIGGRAPH/Eurographics symposium on Computer Animation, SCA &rsquo;11, (New York, NY, USA), pp. 139&ndash;146, Association for Computing Machinery, 2011. event-place: Vancouver, British Columbia, Canada.<br />
<strong>[5]</strong> S. Tregillus and E. Folmer, &ldquo;VR-STEP: Walking-in-Place Using InertialSensing for Hands-Free Navigation,&rdquo; in Proceedings of the 2016 CHIConference on Human Factors in Computing Systems, Association for Computing Machinery, 2016.<br />
<strong>[6] </strong>J. P. Freiwald, O. Ariza, O. Janet, and F. Steinicke, &ldquo;Walking by Cy-cling: A Novel In-Place Locomotion User Interface for Seated VirtualReality Experiences,&rdquo; in Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1&ndash;12, New York, NY, USA: Association for Computing Machinery, 2020.<br />
<strong>[7]</strong> R. G. Boboc, M.-I. Toma, H. Moga, A. N. Panfir, and D. Talab ̆a, &ldquo;AnOmnidirectional System for Navigation in Virtual Environments,&rdquo; technological innovation for the Internet of Things(L. M. Camarinha-Matos, S. Tomic, and P. Grace ̧a, eds.), vol. 394, pp. 192&ndash;199, Berlin,Heidelberg: Springer Berlin Heidelberg, 2013. Series Title: IFIPAdvances in Information and Communication Technology.<br />
<strong>[8]</strong> B. Rymut and B. Kwolek, &ldquo;Mixing Graphics and Compute for Real-Time Multiview Human Body Tracking,&rdquo; in computer Vision and graphics(L. J. Chmielewski, R. Kozera, B.-S. Shin, and K. Wojciechowski, eds.), Cham: Springer International Publishing, 2014. Series Title: Lecture Notes in Computer Science.<br />
<strong>[9]</strong> B. Walther-Franks and D. Wenig, &ldquo;Suspended Walking: A PhysicalLocomotion Interface for Virtual Reality,&rdquo; in entertainment Computing&ndash; ICEC 2013(J. C. Anacleto, ed.), vol. 8215, Berlin, Heidelberg:Springer Berlin Heidelberg, 2013. Series Title: Lecture Notes in computer Science.<br />
<strong>[10]</strong> L. Bruno and J. Pereira, &ldquo;A New Approach to Walking in Place,&rdquo; inHuman-Computer Interaction &ndash; INTERACT 2013(D. Hutchison, ed.), vol. 8119, Berlin, Heidelberg: Springer Berlin Heidelberg, 2013. Series title: Lecture Notes in Computer Science.<br />
<strong>[11]</strong> W. Xu, B. Wang, and Y. Jiang, &ldquo;Multi-target indoor tracking and recognition system with infrared markers for virtual reality,&rdquo; in2017 IEEE2nd Advanced Information Technology, Electronic and AutomationControl Conference (IAEAC), pp. 1549&ndash;1553, Mar. 2017.<br />
<strong>[12]</strong> D. Bicho, P. Gir ̃ao, J. Paulo, and Garrote, &ldquo;Markerless Multi-View-based Multi-User Head Tracking System for Virtual Reality Applications,&rdquo; in2019 IEEE International Conference on Systems, Man and cybernetics, Oct. 2019. ISSN: 2577-1655.<br />
<strong>[13]</strong> A. Kitson and Riecke, &ldquo;Navichair: Evaluating an embodied interface using a pointing task to navigate virtual reality,&rdquo; in ACM Symposium on Spatial User Interaction SUI, pp. 123&ndash;126, 08 2015.<br />
<strong>[14] </strong>M. Nabiyouni and A. Saktheeswaran, &ldquo;Comparing the performance of natural, semi-natural, and non-natural locomotion techniques in virtual reality,&rdquo; in2015 IEEE Virtual Reality (VR), 2015.[15]M. Hudak and Korecko, &ldquo;Walking Pad and Gyroscope-Based ObjectManipulation for Virtual Reality CAVE,&rdquo; in2018 IEEE 18th Inter-national Symposium on Computational Intelligence and Informatics(CINTI), pp. 000283&ndash;000288, Nov. 2018. ISSN: 2471-9269.<br />
<strong>[16]</strong> M. Zank, L. Kern, and A. Kunz, &ldquo;Improvements on a Novel HybridTracking System,&rdquo; in Proceedings of the 7th Augmented Human Inter-national Conference 2016, AH &rsquo;16, (New York, NY, USA), Association for Computing Machinery, 2016. event-place: Geneva, Switzerland.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><strong>[17]</strong> D.-C. Yi, K.-N. Chang, Y.-H. Tai, I.-C. Chen, and Y.-P. Hung, &ldquo;Elastic-Move: Passive Force Feedback Devices for Virtual Reality Locomotion,&rdquo; in2020 IEEE Conference on Virtual Reality and 3D User Inter-faces Abstracts and Workshops (VRW), pp. 766&ndash;767, Mar. 2020.<br />
<strong>[18]</strong> S. Barai and Momin, &ldquo;Outside-in Electromagnetic Tracking Method for augmented and Virtual Reality 6-Degree of Freedom Head-MountedDisplays,&rdquo; in2020 4th International Conference on Intelligent Computing and Control Systems, May 2020.<br />
<strong>[19]</strong> M. Al Zayer and E. Folmer, &ldquo;StereoTrack: 180-Degree Low-CostAcoustic Positional Tracking,&rdquo; in Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play, CHI PLAY &rsquo;18 Extended Abstracts, Association for Computing Machinery, 2018. event-place: Melbourne, VIC, Australia.<br />
<strong>[20]</strong> R. Eklund and C. Erkut, &ldquo;A Positional Infrared Tracking System UsingNon-individualised HRTFs to Simulate a Loudspeaker Setup,&rdquo; inter-activity, Game Creation, Design, Learning, and Innovation(A. Brooks and E. I. Brooks, eds.), Cham: Springer International Publishing, 2020.Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.</span></span></p>

<p style="text-align:justify"><span style="font-size:14px"><span style="color:#000000"><strong>[21]</strong> L. Marie Prinz and T. Mathew, &ldquo;An overview and analysis of publications on locomotion taxonomies,&rdquo; in2021 IEEE Conference on VirtualReality and 3D User Interfaces Abstracts, 2021.<br />
<strong>[22]</strong> C. Boletus, &ldquo;The new era of virtual reality locomotion: A systematic literature review of techniques and a proposed typology,&rdquo; MultimodalTechnologies and Interaction, vol. 1, p. 24, 09 2017.[23]D. A. Bowman and E. Davis, &ldquo;Maintaining spatial orientation during travel in an immersive virtual environment,&rdquo; Presence: Telescope. VirtualEnviron., Dec. 1999.<br />
<strong>[24]</strong> J. J. LaViola Jr, E. Kruijff, R. P. McMahan, D. Bowman, and I. P.Poupyrev,3D user interfaces: theory and practice. Addison-WesleyProfessional, 2017.<br />
<strong>[25]</strong> C. Hand, &ldquo;A survey of 3d interaction techniques,&rdquo; Comput. Graph.Forum, vol. 16, pp. 269&ndash;281, 12 1997.<br />
<strong>[26] </strong>J. Templeman and Denbrook, &ldquo;Virtual locomotion: Walking in place through virtual environments,&rdquo; Presence, 12 1999.<br />
<strong>[27]</strong> M. Nabiyouni and Bowman, &ldquo;A Taxonomy for Designing Walking-Based Locomotion Techniques for Virtual Reality,&rdquo; in2016 Companion on Interactive Surfaces and Spaces, ISS &rsquo;16 Companion, pp. 115&ndash;121, Association for Computing Machinery, 2016.<br />
<strong>[28]</strong> M. Al Zayer and P. MacNeilage, &ldquo;Virtual Locomotion: A Survey,&rdquo; IEEE Transactions on Visualization &amp; Computer Graphics, June 2020.<br />
<strong>[29]</strong> T. van Gemert and J. Bergstr ̈om, &ldquo;Evaluating VR Sickness in VRLocomotion Techniques,&rdquo; in2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, Mar. 2021</span></span></p>

<hr />
<p>&nbsp;</p>
